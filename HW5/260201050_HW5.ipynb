{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDkn--vjlx9I"
      },
      "source": [
        "# HW-5: Malware Classification\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "Suppose your company is struggling with a series of computer virus attacks for the past several months. The viruses were grouped into a few types with some effort. However, it takes a long time to sort out what kind of virus it is when been hit with. Thus, as a senior IT department member, you undertook a project to classify the virus as quickly as possible. You've been given a dataset of the features that may be handy (or not), and  also the associated virus type (target variable). \n",
        "\n",
        "You are supposed to try different classification methods and apply best practices we have seen in the lectures such as grid search, cross validation, regularization etc. To increase your grade you can add more elaboration such as using ensembling or exploiting feature selection/extraction techniques. **An evaluation rubric is provided.**\n",
        "\n",
        "Please prepare a python notebook that describes the steps, present the results as well as your comments. \n",
        "\n",
        "You can download the data (csv file) [here](https://drive.google.com/file/d/1yxbibzUU8bjOyChDVFPfQ4viLduYdk29/view?usp=sharing).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvIdpHi68hC0"
      },
      "source": [
        "Importing virus data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvQVzSsI8mtc"
      },
      "source": [
        "Importing required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-Nbx2fLf5LQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "YRvlySJy5Ic9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('hw5_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxxsbcZ5VKc",
        "outputId": "8f4b48cf-12ed-42b8-cca9-a7e65093b029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of       Virtual  Offset     loc       Import  Imports     var     Forwarder  \\\n",
              "0         3.0     3.0   689.0    18.000000      6.0   890.0      6.000000   \n",
              "1         3.0     3.0   583.0    15.000000      5.0  1574.0   8640.382774   \n",
              "2         3.0     4.0  2796.0    15.000000      5.0   625.0      5.000000   \n",
              "3         3.0     3.0   373.0  2726.071722      9.0   615.0      9.000000   \n",
              "4         3.0     3.0    77.0    12.000000      4.0    66.0  91945.635853   \n",
              "...       ...     ...     ...          ...      ...     ...           ...   \n",
              "4994      4.0     4.0   118.0     0.000000      3.0     0.0      0.000000   \n",
              "4995      3.0     3.0    27.0    12.000000      4.0    38.0      4.000000   \n",
              "4996      3.0     3.0    16.0    12.000000      4.0     7.0      4.000000   \n",
              "4997      4.0     4.0  2810.0     0.000000      2.0   666.0      0.000000   \n",
              "4998      3.0     4.0  1587.0    21.000000      7.0   526.0      7.000000   \n",
              "\n",
              "      UINT          LONG          BOOL  ...          Img99         Img100  \\\n",
              "0     39.0     17.000000     88.000000  ... -208196.847822  149454.443336   \n",
              "1      6.0      7.000000     30.000000  ...   36209.864030  221318.549792   \n",
              "2     58.0     11.000000    152.000000  ...   88398.670923   66550.556919   \n",
              "3     16.0  98583.277889     34.000000  ... -157101.258148  -60336.395075   \n",
              "4      3.0      0.000000      5.000000  ...   32595.648968 -228909.737896   \n",
              "...    ...           ...           ...  ...            ...            ...   \n",
              "4994   7.0      0.000000     19.000000  ...  -73364.892264   56908.607312   \n",
              "4995   3.0      0.000000  84772.903087  ...  -91323.369562  101628.992660   \n",
              "4996   9.0      0.000000     16.000000  ...   26135.603443  172273.939349   \n",
              "4997  14.0      9.000000     26.000000  ...  -70335.106256  -21680.148668   \n",
              "4998  34.0      5.000000  61033.550970  ...  -14702.601507   18593.024103   \n",
              "\n",
              "             Img101         Img102         Img103         Img104  \\\n",
              "0     330552.774213  133907.410063   44038.800343   55156.067737   \n",
              "1      -1568.194718   22651.037591 -144906.975987  -33489.566102   \n",
              "2       5404.362294   13947.925003  -48559.885445  257023.562444   \n",
              "3     157629.928962  117458.409503   62076.273381   98733.489947   \n",
              "4     -87033.363460  131606.196188 -118625.690367   89326.297602   \n",
              "...             ...            ...            ...            ...   \n",
              "4994   17895.279817   -4589.198675  103618.354421 -126164.290238   \n",
              "4995    8812.429736  -41149.748369  -56293.578460   87524.257112   \n",
              "4996   74515.593674   79555.659907   79230.809864   92047.004360   \n",
              "4997   11900.591113    8015.793354 -105036.351181  -33386.286236   \n",
              "4998    2249.256720   45713.524900  -16239.518388  -78553.054374   \n",
              "\n",
              "             Img105         Img106    Img107  target  \n",
              "0     -77588.974897  171979.000000  162674.0       2  \n",
              "1     157701.356695    7702.000000    6551.0       8  \n",
              "2    -204889.973046  151324.169975   12946.0       6  \n",
              "3     -51461.636374  122247.000000   98621.0       4  \n",
              "4     -84991.427204   15501.000000   11864.0       1  \n",
              "...             ...            ...       ...     ...  \n",
              "4994  -24272.971224    7100.000000    6002.0       4  \n",
              "4995 -200433.940978   69304.000000   65638.0       3  \n",
              "4996   94829.356066   71789.000000   68354.0       3  \n",
              "4997  169699.674511   89989.000000   70139.0       2  \n",
              "4998 -115903.637264    9394.000000    3145.0       9  \n",
              "\n",
              "[4999 rows x 1805 columns]>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "mL27Urp_5eeA",
        "outputId": "62037936-aa15-48f5-f71e-11b9cbd94946"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Virtual</th>\n",
              "      <th>Offset</th>\n",
              "      <th>loc</th>\n",
              "      <th>Import</th>\n",
              "      <th>Imports</th>\n",
              "      <th>var</th>\n",
              "      <th>Forwarder</th>\n",
              "      <th>UINT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>BOOL</th>\n",
              "      <th>...</th>\n",
              "      <th>Img99</th>\n",
              "      <th>Img100</th>\n",
              "      <th>Img101</th>\n",
              "      <th>Img102</th>\n",
              "      <th>Img103</th>\n",
              "      <th>Img104</th>\n",
              "      <th>Img105</th>\n",
              "      <th>Img106</th>\n",
              "      <th>Img107</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "      <td>4999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2413.316145</td>\n",
              "      <td>2659.311487</td>\n",
              "      <td>4424.891220</td>\n",
              "      <td>2291.214822</td>\n",
              "      <td>2512.272757</td>\n",
              "      <td>3470.164710</td>\n",
              "      <td>2612.176503</td>\n",
              "      <td>2472.228927</td>\n",
              "      <td>2554.660865</td>\n",
              "      <td>2452.442360</td>\n",
              "      <td>...</td>\n",
              "      <td>14331.213118</td>\n",
              "      <td>9358.953517</td>\n",
              "      <td>23654.548237</td>\n",
              "      <td>8540.786955</td>\n",
              "      <td>17432.020184</td>\n",
              "      <td>22032.274639</td>\n",
              "      <td>9505.453675</td>\n",
              "      <td>70574.781259</td>\n",
              "      <td>54803.742148</td>\n",
              "      <td>4.086817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12506.374487</td>\n",
              "      <td>13159.966494</td>\n",
              "      <td>13604.624599</td>\n",
              "      <td>11996.827931</td>\n",
              "      <td>12656.467627</td>\n",
              "      <td>12442.838259</td>\n",
              "      <td>13026.935701</td>\n",
              "      <td>12695.076990</td>\n",
              "      <td>12533.327183</td>\n",
              "      <td>12280.398873</td>\n",
              "      <td>...</td>\n",
              "      <td>108685.996366</td>\n",
              "      <td>107161.612891</td>\n",
              "      <td>109735.456647</td>\n",
              "      <td>105281.088434</td>\n",
              "      <td>107423.247504</td>\n",
              "      <td>109858.578170</td>\n",
              "      <td>106876.987983</td>\n",
              "      <td>67871.038272</td>\n",
              "      <td>53395.251409</td>\n",
              "      <td>2.677785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-399471.378431</td>\n",
              "      <td>-344924.897141</td>\n",
              "      <td>-348906.065760</td>\n",
              "      <td>-379757.698729</td>\n",
              "      <td>-345576.170139</td>\n",
              "      <td>-410986.193796</td>\n",
              "      <td>-355679.953652</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-57945.624535</td>\n",
              "      <td>-63567.620933</td>\n",
              "      <td>-50475.672159</td>\n",
              "      <td>-63194.878910</td>\n",
              "      <td>-55114.830841</td>\n",
              "      <td>-50016.264131</td>\n",
              "      <td>-63550.766114</td>\n",
              "      <td>13387.000000</td>\n",
              "      <td>8117.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>526.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>407.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>13494.353190</td>\n",
              "      <td>9797.650967</td>\n",
              "      <td>22385.687582</td>\n",
              "      <td>10410.067259</td>\n",
              "      <td>18424.422329</td>\n",
              "      <td>21454.161075</td>\n",
              "      <td>9709.062906</td>\n",
              "      <td>67890.000000</td>\n",
              "      <td>49865.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1977.500000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1330.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>87246.586847</td>\n",
              "      <td>82454.969088</td>\n",
              "      <td>95044.827729</td>\n",
              "      <td>80084.458079</td>\n",
              "      <td>87543.264657</td>\n",
              "      <td>96288.509357</td>\n",
              "      <td>82107.827536</td>\n",
              "      <td>88771.000000</td>\n",
              "      <td>68589.500000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>99416.349008</td>\n",
              "      <td>99973.742656</td>\n",
              "      <td>107775.000000</td>\n",
              "      <td>99364.479576</td>\n",
              "      <td>99838.164777</td>\n",
              "      <td>100278.830725</td>\n",
              "      <td>99673.225000</td>\n",
              "      <td>100002.864718</td>\n",
              "      <td>99039.014532</td>\n",
              "      <td>99262.954988</td>\n",
              "      <td>...</td>\n",
              "      <td>500390.536696</td>\n",
              "      <td>358149.487611</td>\n",
              "      <td>465889.867881</td>\n",
              "      <td>364890.436486</td>\n",
              "      <td>389119.972128</td>\n",
              "      <td>443685.869973</td>\n",
              "      <td>437127.690431</td>\n",
              "      <td>412076.355373</td>\n",
              "      <td>300241.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1805 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Virtual        Offset            loc        Import       Imports  \\\n",
              "count   4999.000000   4999.000000    4999.000000   4999.000000   4999.000000   \n",
              "mean    2413.316145   2659.311487    4424.891220   2291.214822   2512.272757   \n",
              "std    12506.374487  13159.966494   13604.624599  11996.827931  12656.467627   \n",
              "min        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
              "25%        3.000000      3.000000      77.000000      6.000000      4.000000   \n",
              "50%        3.000000      3.000000     526.000000     12.000000      4.000000   \n",
              "75%        4.000000      4.000000    1977.500000     18.000000      7.000000   \n",
              "max    99416.349008  99973.742656  107775.000000  99364.479576  99838.164777   \n",
              "\n",
              "                 var     Forwarder           UINT          LONG          BOOL  \\\n",
              "count    4999.000000   4999.000000    4999.000000   4999.000000   4999.000000   \n",
              "mean     3470.164710   2612.176503    2472.228927   2554.660865   2452.442360   \n",
              "std     12442.838259  13026.935701   12695.076990  12533.327183  12280.398873   \n",
              "min         0.000000      0.000000       0.000000      0.000000      0.000000   \n",
              "25%        37.000000      2.000000       6.000000      0.000000     13.000000   \n",
              "50%       407.000000      4.000000      12.000000      5.000000     20.000000   \n",
              "75%      1330.500000      6.000000      18.000000      9.000000     38.000000   \n",
              "max    100278.830725  99673.225000  100002.864718  99039.014532  99262.954988   \n",
              "\n",
              "       ...          Img99         Img100         Img101         Img102  \\\n",
              "count  ...    4999.000000    4999.000000    4999.000000    4999.000000   \n",
              "mean   ...   14331.213118    9358.953517   23654.548237    8540.786955   \n",
              "std    ...  108685.996366  107161.612891  109735.456647  105281.088434   \n",
              "min    ... -399471.378431 -344924.897141 -348906.065760 -379757.698729   \n",
              "25%    ...  -57945.624535  -63567.620933  -50475.672159  -63194.878910   \n",
              "50%    ...   13494.353190    9797.650967   22385.687582   10410.067259   \n",
              "75%    ...   87246.586847   82454.969088   95044.827729   80084.458079   \n",
              "max    ...  500390.536696  358149.487611  465889.867881  364890.436486   \n",
              "\n",
              "              Img103         Img104         Img105         Img106  \\\n",
              "count    4999.000000    4999.000000    4999.000000    4999.000000   \n",
              "mean    17432.020184   22032.274639    9505.453675   70574.781259   \n",
              "std    107423.247504  109858.578170  106876.987983   67871.038272   \n",
              "min   -345576.170139 -410986.193796 -355679.953652       0.000000   \n",
              "25%    -55114.830841  -50016.264131  -63550.766114   13387.000000   \n",
              "50%     18424.422329   21454.161075    9709.062906   67890.000000   \n",
              "75%     87543.264657   96288.509357   82107.827536   88771.000000   \n",
              "max    389119.972128  443685.869973  437127.690431  412076.355373   \n",
              "\n",
              "              Img107       target  \n",
              "count    4999.000000  4999.000000  \n",
              "mean    54803.742148     4.086817  \n",
              "std     53395.251409     2.677785  \n",
              "min         0.000000     1.000000  \n",
              "25%      8117.000000     2.000000  \n",
              "50%     49865.000000     3.000000  \n",
              "75%     68589.500000     6.000000  \n",
              "max    300241.000000     9.000000  \n",
              "\n",
              "[8 rows x 1805 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IccumyaRrya"
      },
      "source": [
        "First let see mutual information. Mutual Information measures how much information one variable gives about the other. In our case, we apply to input and target variables to determine how much information an input variable carries about the target variable: I(X;y).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tPlAmdoZw3s"
      },
      "source": [
        "**Choosing the feature selection method:**\n",
        "\n",
        "**Filter method:** the criteria is built inside the search algorithm itself without refereance to the learner.\n",
        "\n",
        "**Wrapping:** Criteria is built inside what the learner wants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "jfx8rPIIb7pB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import GenericUnivariateSelect\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ovAqLUZ0SWu"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO34PcO0s5EZ"
      },
      "source": [
        "Split the data into features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "vGT_q-fScRi_"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['target'], axis=1)\n",
        "y = df['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXicTVGreOJ"
      },
      "source": [
        "Split the data into training and test sets because right thing to do is not seeing test data.Feature selector should not seen the test data while computing mutual information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DdrblgXtW0g7",
        "outputId": "ef67f364-a095-4d26-9416-c57a7d272e1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Virtual</th>\n",
              "      <th>Offset</th>\n",
              "      <th>loc</th>\n",
              "      <th>Import</th>\n",
              "      <th>Imports</th>\n",
              "      <th>var</th>\n",
              "      <th>Forwarder</th>\n",
              "      <th>UINT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>BOOL</th>\n",
              "      <th>...</th>\n",
              "      <th>Img99</th>\n",
              "      <th>Img100</th>\n",
              "      <th>Img101</th>\n",
              "      <th>Img102</th>\n",
              "      <th>Img103</th>\n",
              "      <th>Img104</th>\n",
              "      <th>Img105</th>\n",
              "      <th>Img106</th>\n",
              "      <th>Img107</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>39.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-208196.847822</td>\n",
              "      <td>149454.443336</td>\n",
              "      <td>330552.774213</td>\n",
              "      <td>133907.410063</td>\n",
              "      <td>44038.800343</td>\n",
              "      <td>55156.067737</td>\n",
              "      <td>-77588.974897</td>\n",
              "      <td>171979.000000</td>\n",
              "      <td>162674.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1574.0</td>\n",
              "      <td>8640.382774</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>36209.864030</td>\n",
              "      <td>221318.549792</td>\n",
              "      <td>-1568.194718</td>\n",
              "      <td>22651.037591</td>\n",
              "      <td>-144906.975987</td>\n",
              "      <td>-33489.566102</td>\n",
              "      <td>157701.356695</td>\n",
              "      <td>7702.000000</td>\n",
              "      <td>6551.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2796.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>625.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>58.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>88398.670923</td>\n",
              "      <td>66550.556919</td>\n",
              "      <td>5404.362294</td>\n",
              "      <td>13947.925003</td>\n",
              "      <td>-48559.885445</td>\n",
              "      <td>257023.562444</td>\n",
              "      <td>-204889.973046</td>\n",
              "      <td>151324.169975</td>\n",
              "      <td>12946.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>2726.071722</td>\n",
              "      <td>9.0</td>\n",
              "      <td>615.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>98583.277889</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-157101.258148</td>\n",
              "      <td>-60336.395075</td>\n",
              "      <td>157629.928962</td>\n",
              "      <td>117458.409503</td>\n",
              "      <td>62076.273381</td>\n",
              "      <td>98733.489947</td>\n",
              "      <td>-51461.636374</td>\n",
              "      <td>122247.000000</td>\n",
              "      <td>98621.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>91945.635853</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>32595.648968</td>\n",
              "      <td>-228909.737896</td>\n",
              "      <td>-87033.363460</td>\n",
              "      <td>131606.196188</td>\n",
              "      <td>-118625.690367</td>\n",
              "      <td>89326.297602</td>\n",
              "      <td>-84991.427204</td>\n",
              "      <td>15501.000000</td>\n",
              "      <td>11864.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-73364.892264</td>\n",
              "      <td>56908.607312</td>\n",
              "      <td>17895.279817</td>\n",
              "      <td>-4589.198675</td>\n",
              "      <td>103618.354421</td>\n",
              "      <td>-126164.290238</td>\n",
              "      <td>-24272.971224</td>\n",
              "      <td>7100.000000</td>\n",
              "      <td>6002.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84772.903087</td>\n",
              "      <td>...</td>\n",
              "      <td>-91323.369562</td>\n",
              "      <td>101628.992660</td>\n",
              "      <td>8812.429736</td>\n",
              "      <td>-41149.748369</td>\n",
              "      <td>-56293.578460</td>\n",
              "      <td>87524.257112</td>\n",
              "      <td>-200433.940978</td>\n",
              "      <td>69304.000000</td>\n",
              "      <td>65638.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>26135.603443</td>\n",
              "      <td>172273.939349</td>\n",
              "      <td>74515.593674</td>\n",
              "      <td>79555.659907</td>\n",
              "      <td>79230.809864</td>\n",
              "      <td>92047.004360</td>\n",
              "      <td>94829.356066</td>\n",
              "      <td>71789.000000</td>\n",
              "      <td>68354.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2810.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-70335.106256</td>\n",
              "      <td>-21680.148668</td>\n",
              "      <td>11900.591113</td>\n",
              "      <td>8015.793354</td>\n",
              "      <td>-105036.351181</td>\n",
              "      <td>-33386.286236</td>\n",
              "      <td>169699.674511</td>\n",
              "      <td>89989.000000</td>\n",
              "      <td>70139.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1587.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>61033.550970</td>\n",
              "      <td>...</td>\n",
              "      <td>-14702.601507</td>\n",
              "      <td>18593.024103</td>\n",
              "      <td>2249.256720</td>\n",
              "      <td>45713.524900</td>\n",
              "      <td>-16239.518388</td>\n",
              "      <td>-78553.054374</td>\n",
              "      <td>-115903.637264</td>\n",
              "      <td>9394.000000</td>\n",
              "      <td>3145.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4999 rows × 1805 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Virtual  Offset     loc       Import  Imports     var     Forwarder  \\\n",
              "0         3.0     3.0   689.0    18.000000      6.0   890.0      6.000000   \n",
              "1         3.0     3.0   583.0    15.000000      5.0  1574.0   8640.382774   \n",
              "2         3.0     4.0  2796.0    15.000000      5.0   625.0      5.000000   \n",
              "3         3.0     3.0   373.0  2726.071722      9.0   615.0      9.000000   \n",
              "4         3.0     3.0    77.0    12.000000      4.0    66.0  91945.635853   \n",
              "...       ...     ...     ...          ...      ...     ...           ...   \n",
              "4994      4.0     4.0   118.0     0.000000      3.0     0.0      0.000000   \n",
              "4995      3.0     3.0    27.0    12.000000      4.0    38.0      4.000000   \n",
              "4996      3.0     3.0    16.0    12.000000      4.0     7.0      4.000000   \n",
              "4997      4.0     4.0  2810.0     0.000000      2.0   666.0      0.000000   \n",
              "4998      3.0     4.0  1587.0    21.000000      7.0   526.0      7.000000   \n",
              "\n",
              "      UINT          LONG          BOOL  ...          Img99         Img100  \\\n",
              "0     39.0     17.000000     88.000000  ... -208196.847822  149454.443336   \n",
              "1      6.0      7.000000     30.000000  ...   36209.864030  221318.549792   \n",
              "2     58.0     11.000000    152.000000  ...   88398.670923   66550.556919   \n",
              "3     16.0  98583.277889     34.000000  ... -157101.258148  -60336.395075   \n",
              "4      3.0      0.000000      5.000000  ...   32595.648968 -228909.737896   \n",
              "...    ...           ...           ...  ...            ...            ...   \n",
              "4994   7.0      0.000000     19.000000  ...  -73364.892264   56908.607312   \n",
              "4995   3.0      0.000000  84772.903087  ...  -91323.369562  101628.992660   \n",
              "4996   9.0      0.000000     16.000000  ...   26135.603443  172273.939349   \n",
              "4997  14.0      9.000000     26.000000  ...  -70335.106256  -21680.148668   \n",
              "4998  34.0      5.000000  61033.550970  ...  -14702.601507   18593.024103   \n",
              "\n",
              "             Img101         Img102         Img103         Img104  \\\n",
              "0     330552.774213  133907.410063   44038.800343   55156.067737   \n",
              "1      -1568.194718   22651.037591 -144906.975987  -33489.566102   \n",
              "2       5404.362294   13947.925003  -48559.885445  257023.562444   \n",
              "3     157629.928962  117458.409503   62076.273381   98733.489947   \n",
              "4     -87033.363460  131606.196188 -118625.690367   89326.297602   \n",
              "...             ...            ...            ...            ...   \n",
              "4994   17895.279817   -4589.198675  103618.354421 -126164.290238   \n",
              "4995    8812.429736  -41149.748369  -56293.578460   87524.257112   \n",
              "4996   74515.593674   79555.659907   79230.809864   92047.004360   \n",
              "4997   11900.591113    8015.793354 -105036.351181  -33386.286236   \n",
              "4998    2249.256720   45713.524900  -16239.518388  -78553.054374   \n",
              "\n",
              "             Img105         Img106    Img107  target  \n",
              "0     -77588.974897  171979.000000  162674.0       2  \n",
              "1     157701.356695    7702.000000    6551.0       8  \n",
              "2    -204889.973046  151324.169975   12946.0       6  \n",
              "3     -51461.636374  122247.000000   98621.0       4  \n",
              "4     -84991.427204   15501.000000   11864.0       1  \n",
              "...             ...            ...       ...     ...  \n",
              "4994  -24272.971224    7100.000000    6002.0       4  \n",
              "4995 -200433.940978   69304.000000   65638.0       3  \n",
              "4996   94829.356066   71789.000000   68354.0       3  \n",
              "4997  169699.674511   89989.000000   70139.0       2  \n",
              "4998 -115903.637264    9394.000000    3145.0       9  \n",
              "\n",
              "[4999 rows x 1805 columns]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_I2fYDMXAHb"
      },
      "source": [
        "Dataframe without target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hJt7q0akWj7n",
        "outputId": "8f7f2c12-b816-4f5f-d13b-3d6f345adcf4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Virtual</th>\n",
              "      <th>Offset</th>\n",
              "      <th>loc</th>\n",
              "      <th>Import</th>\n",
              "      <th>Imports</th>\n",
              "      <th>var</th>\n",
              "      <th>Forwarder</th>\n",
              "      <th>UINT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>BOOL</th>\n",
              "      <th>...</th>\n",
              "      <th>Img98</th>\n",
              "      <th>Img99</th>\n",
              "      <th>Img100</th>\n",
              "      <th>Img101</th>\n",
              "      <th>Img102</th>\n",
              "      <th>Img103</th>\n",
              "      <th>Img104</th>\n",
              "      <th>Img105</th>\n",
              "      <th>Img106</th>\n",
              "      <th>Img107</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>39.0</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-8960.240039</td>\n",
              "      <td>-208196.847822</td>\n",
              "      <td>149454.443336</td>\n",
              "      <td>330552.774213</td>\n",
              "      <td>133907.410063</td>\n",
              "      <td>44038.800343</td>\n",
              "      <td>55156.067737</td>\n",
              "      <td>-77588.974897</td>\n",
              "      <td>171979.000000</td>\n",
              "      <td>162674.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1574.0</td>\n",
              "      <td>8640.382774</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-64135.213433</td>\n",
              "      <td>36209.864030</td>\n",
              "      <td>221318.549792</td>\n",
              "      <td>-1568.194718</td>\n",
              "      <td>22651.037591</td>\n",
              "      <td>-144906.975987</td>\n",
              "      <td>-33489.566102</td>\n",
              "      <td>157701.356695</td>\n",
              "      <td>7702.000000</td>\n",
              "      <td>6551.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2796.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>625.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>58.0</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-55210.112217</td>\n",
              "      <td>88398.670923</td>\n",
              "      <td>66550.556919</td>\n",
              "      <td>5404.362294</td>\n",
              "      <td>13947.925003</td>\n",
              "      <td>-48559.885445</td>\n",
              "      <td>257023.562444</td>\n",
              "      <td>-204889.973046</td>\n",
              "      <td>151324.169975</td>\n",
              "      <td>12946.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>2726.071722</td>\n",
              "      <td>9.0</td>\n",
              "      <td>615.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>98583.277889</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>85127.672835</td>\n",
              "      <td>-157101.258148</td>\n",
              "      <td>-60336.395075</td>\n",
              "      <td>157629.928962</td>\n",
              "      <td>117458.409503</td>\n",
              "      <td>62076.273381</td>\n",
              "      <td>98733.489947</td>\n",
              "      <td>-51461.636374</td>\n",
              "      <td>122247.000000</td>\n",
              "      <td>98621.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>91945.635853</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>190454.371505</td>\n",
              "      <td>32595.648968</td>\n",
              "      <td>-228909.737896</td>\n",
              "      <td>-87033.363460</td>\n",
              "      <td>131606.196188</td>\n",
              "      <td>-118625.690367</td>\n",
              "      <td>89326.297602</td>\n",
              "      <td>-84991.427204</td>\n",
              "      <td>15501.000000</td>\n",
              "      <td>11864.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>51103.570346</td>\n",
              "      <td>-73364.892264</td>\n",
              "      <td>56908.607312</td>\n",
              "      <td>17895.279817</td>\n",
              "      <td>-4589.198675</td>\n",
              "      <td>103618.354421</td>\n",
              "      <td>-126164.290238</td>\n",
              "      <td>-24272.971224</td>\n",
              "      <td>7100.000000</td>\n",
              "      <td>6002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84772.903087</td>\n",
              "      <td>...</td>\n",
              "      <td>-115886.282610</td>\n",
              "      <td>-91323.369562</td>\n",
              "      <td>101628.992660</td>\n",
              "      <td>8812.429736</td>\n",
              "      <td>-41149.748369</td>\n",
              "      <td>-56293.578460</td>\n",
              "      <td>87524.257112</td>\n",
              "      <td>-200433.940978</td>\n",
              "      <td>69304.000000</td>\n",
              "      <td>65638.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-112855.252330</td>\n",
              "      <td>26135.603443</td>\n",
              "      <td>172273.939349</td>\n",
              "      <td>74515.593674</td>\n",
              "      <td>79555.659907</td>\n",
              "      <td>79230.809864</td>\n",
              "      <td>92047.004360</td>\n",
              "      <td>94829.356066</td>\n",
              "      <td>71789.000000</td>\n",
              "      <td>68354.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2810.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-46285.526022</td>\n",
              "      <td>-70335.106256</td>\n",
              "      <td>-21680.148668</td>\n",
              "      <td>11900.591113</td>\n",
              "      <td>8015.793354</td>\n",
              "      <td>-105036.351181</td>\n",
              "      <td>-33386.286236</td>\n",
              "      <td>169699.674511</td>\n",
              "      <td>89989.000000</td>\n",
              "      <td>70139.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1587.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>61033.550970</td>\n",
              "      <td>...</td>\n",
              "      <td>-117974.393716</td>\n",
              "      <td>-14702.601507</td>\n",
              "      <td>18593.024103</td>\n",
              "      <td>2249.256720</td>\n",
              "      <td>45713.524900</td>\n",
              "      <td>-16239.518388</td>\n",
              "      <td>-78553.054374</td>\n",
              "      <td>-115903.637264</td>\n",
              "      <td>9394.000000</td>\n",
              "      <td>3145.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4999 rows × 1804 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Virtual  Offset     loc       Import  Imports     var     Forwarder  \\\n",
              "0         3.0     3.0   689.0    18.000000      6.0   890.0      6.000000   \n",
              "1         3.0     3.0   583.0    15.000000      5.0  1574.0   8640.382774   \n",
              "2         3.0     4.0  2796.0    15.000000      5.0   625.0      5.000000   \n",
              "3         3.0     3.0   373.0  2726.071722      9.0   615.0      9.000000   \n",
              "4         3.0     3.0    77.0    12.000000      4.0    66.0  91945.635853   \n",
              "...       ...     ...     ...          ...      ...     ...           ...   \n",
              "4994      4.0     4.0   118.0     0.000000      3.0     0.0      0.000000   \n",
              "4995      3.0     3.0    27.0    12.000000      4.0    38.0      4.000000   \n",
              "4996      3.0     3.0    16.0    12.000000      4.0     7.0      4.000000   \n",
              "4997      4.0     4.0  2810.0     0.000000      2.0   666.0      0.000000   \n",
              "4998      3.0     4.0  1587.0    21.000000      7.0   526.0      7.000000   \n",
              "\n",
              "      UINT          LONG          BOOL  ...          Img98          Img99  \\\n",
              "0     39.0     17.000000     88.000000  ...   -8960.240039 -208196.847822   \n",
              "1      6.0      7.000000     30.000000  ...  -64135.213433   36209.864030   \n",
              "2     58.0     11.000000    152.000000  ...  -55210.112217   88398.670923   \n",
              "3     16.0  98583.277889     34.000000  ...   85127.672835 -157101.258148   \n",
              "4      3.0      0.000000      5.000000  ...  190454.371505   32595.648968   \n",
              "...    ...           ...           ...  ...            ...            ...   \n",
              "4994   7.0      0.000000     19.000000  ...   51103.570346  -73364.892264   \n",
              "4995   3.0      0.000000  84772.903087  ... -115886.282610  -91323.369562   \n",
              "4996   9.0      0.000000     16.000000  ... -112855.252330   26135.603443   \n",
              "4997  14.0      9.000000     26.000000  ...  -46285.526022  -70335.106256   \n",
              "4998  34.0      5.000000  61033.550970  ... -117974.393716  -14702.601507   \n",
              "\n",
              "             Img100         Img101         Img102         Img103  \\\n",
              "0     149454.443336  330552.774213  133907.410063   44038.800343   \n",
              "1     221318.549792   -1568.194718   22651.037591 -144906.975987   \n",
              "2      66550.556919    5404.362294   13947.925003  -48559.885445   \n",
              "3     -60336.395075  157629.928962  117458.409503   62076.273381   \n",
              "4    -228909.737896  -87033.363460  131606.196188 -118625.690367   \n",
              "...             ...            ...            ...            ...   \n",
              "4994   56908.607312   17895.279817   -4589.198675  103618.354421   \n",
              "4995  101628.992660    8812.429736  -41149.748369  -56293.578460   \n",
              "4996  172273.939349   74515.593674   79555.659907   79230.809864   \n",
              "4997  -21680.148668   11900.591113    8015.793354 -105036.351181   \n",
              "4998   18593.024103    2249.256720   45713.524900  -16239.518388   \n",
              "\n",
              "             Img104         Img105         Img106    Img107  \n",
              "0      55156.067737  -77588.974897  171979.000000  162674.0  \n",
              "1     -33489.566102  157701.356695    7702.000000    6551.0  \n",
              "2     257023.562444 -204889.973046  151324.169975   12946.0  \n",
              "3      98733.489947  -51461.636374  122247.000000   98621.0  \n",
              "4      89326.297602  -84991.427204   15501.000000   11864.0  \n",
              "...             ...            ...            ...       ...  \n",
              "4994 -126164.290238  -24272.971224    7100.000000    6002.0  \n",
              "4995   87524.257112 -200433.940978   69304.000000   65638.0  \n",
              "4996   92047.004360   94829.356066   71789.000000   68354.0  \n",
              "4997  -33386.286236  169699.674511   89989.000000   70139.0  \n",
              "4998  -78553.054374 -115903.637264    9394.000000    3145.0  \n",
              "\n",
              "[4999 rows x 1804 columns]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiT1JgH7XCeh"
      },
      "source": [
        "Target "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3Nf9YLW7qA",
        "outputId": "8b02c80f-eb09-4f6e-f94f-adac1fe63fb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       2\n",
              "1       8\n",
              "2       6\n",
              "3       4\n",
              "4       1\n",
              "       ..\n",
              "4994    4\n",
              "4995    3\n",
              "4996    3\n",
              "4997    2\n",
              "4998    9\n",
              "Name: target, Length: 4999, dtype: int64"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spliting the data into feature and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "xzn0eXHIb0iM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.21, random_state=55)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GNV3Olzr5WX"
      },
      "source": [
        "To select the top n features, we need a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Ju6HxSC2gH21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy:  0.8925819819819821\n"
          ]
        }
      ],
      "source": [
        "feature_selection_model = RandomForestClassifier(n_estimators=100, random_state=55)\n",
        "print(\"Random Forest Accuracy: \", cross_val_score(feature_selection_model, X, y, cv=5).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZcis4ze9KT"
      },
      "source": [
        "Trying different n values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvHJXW73vD1b"
      },
      "source": [
        "**`Feature Selection with chi squared: NOT GOOD CHOICE `**\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "II put the code in quotes and showed the output as a comment below. Otherwise it was preventing the file from working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "hT-zVrpQwd9X"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' from sklearn.feature_selection import SelectKBest, chi2\\n\\nfor n in [25, 50, 100, 200]:\\n    chi2_select = SelectKBest(score_func=chi2, k=n)\\n    X_train_selected = chi2_select.fit_transform(X_train, y_train)\\n    X_test_selected = chi2_select.transform(X_test)\\n    selected_features = X.columns[chi2_select.get_support()] '"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\" from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "for n in [25, 50, 100, 200]:\n",
        "    chi2_select = SelectKBest(score_func=chi2, k=n)\n",
        "    X_train_selected = chi2_select.fit_transform(X_train, y_train)\n",
        "    X_test_selected = chi2_select.transform(X_test)\n",
        "    selected_features = X.columns[chi2_select.get_support()] \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB2Fj63kwyZ1"
      },
      "source": [
        "As you see chi squared test requires non-negative input.Solution to this problem is to transform the input data so that it is non-negative. But I think it is not a wise choice. So I will continue with mutual information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmxd42Ugicpl"
      },
      "source": [
        "**`Feature Selection with mutual information `**\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YBEGeuDByrb_"
      },
      "source": [
        "I extracted the feature N= 100 and 200 because it took too long to process and gave errors. Also I added N=35 for compare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKj1E_fye5FI",
        "outputId": "7aa1b736-bd6e-4e41-93e4-d904226f17d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n = 25: score = 0.881\n",
            "n = 35: score = 0.893\n",
            "n = 50: score = 0.900\n"
          ]
        }
      ],
      "source": [
        "for n in [25, 35, 50]:\n",
        "    mf_select = GenericUnivariateSelect(score_func=mutual_info_classif,mode=\"k_best\", param=n)\n",
        "    X_train_selected = mf_select.fit_transform(X_train, y_train)\n",
        "    X_test_selected = mf_select.transform(X_test)\n",
        "    selected_features = X.columns[mf_select.get_support()]\n",
        "\n",
        "    # Fit and evaluate the model with the selected features\n",
        "    feature_selection_model.fit(X_train_selected, y_train)\n",
        "    score = feature_selection_model.score(X_test_selected, y_test)\n",
        "    print(\"n = \" + str(n) + \": score = \" + str(score)[:5])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "ks = [i for i in range(1,X.shape[1])]\n",
        "ac = []\n",
        "for k in ks:\n",
        "  select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=k)\n",
        "  X_k = select.fit_transform(X, y)\n",
        "  score = cross_val_score(feature_selection_model, X_k, y, cv=5).mean()\n",
        "  ac.append( score )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CV Accuracy')"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(ks, ac)\n",
        "plt.xlabel('n')\n",
        "plt.ylabel('CV Accuracy')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wYBXz86LaHzt"
      },
      "source": [
        "n = 50 is the best choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apQdB1H9F4qB"
      },
      "source": [
        "Lets see if selected features choosen properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyHYnbqX0737",
        "outputId": "06f1e89b-cfaa-417f-8669-82e5db13613d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUQdTOCHzVIf",
        "outputId": "f7b29f43-2f45-4b41-e914-4147cf752762"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['dd', 'db', 'ent_q_diffs_19', 'ent_q_diffs_median', 'ent_q_diffs_min',\n",
              "       'ent_q_diff_diffs_0_median', 'ent_q_diff_diffs_1_mean',\n",
              "       'ent_q_diff_diffs_1_median', 'ent_q_diff_diffs_1_max',\n",
              "       'ent_q_diff_diffs_1_min', 'ent_q_diff_diffs_2_mean',\n",
              "       'ent_q_diff_diffs_2_median', 'ent_q_diff_diffs_2_max',\n",
              "       'ent_q_diff_diffs_2_min', 'ent_q_diff_diffs_2_max-min',\n",
              "       'ent_q_diff_diffs_3_median', 'ent_q_diff_diffs_3_min', 'ent_p_0',\n",
              "       'ent_p_1', 'ent_p_2', 'ent_p_3', 'ent_p_4', 'ent_p_5', 'ent_p_6',\n",
              "       'ent_p_7', 'ent_p_8', 'ent_p_9', 'ent_p_10', 'ent_p_11', 'ent_p_12',\n",
              "       'ent_p_14', 'ent_p_diffs_0', 'ent_p_diffs_3', 'ent_p_diffs_4',\n",
              "       'ent_p_diffs_5', 'ent_p_diffs_7', 'ent_p_diffs_8',\n",
              "       'section_names_.data', 'section_names_.rdata', 'TB_07', 'FileSize',\n",
              "       'dd_rdata', 'db3_rdata', 'Img17', 'Img43', 'line_count_asm', 'size_asm',\n",
              "       'ExtendedAscii', 'Img106', 'Img107'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6osVBvlYw1uv"
      },
      "source": [
        "\n",
        "**`Recreating the dataframe with selected features and their target values. For N=50 `**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Kb_IOx2FvcS4"
      },
      "outputs": [],
      "source": [
        "X = df[selected_features]\n",
        "y = df[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "jVt1OYt-vs4h"
      },
      "outputs": [],
      "source": [
        "selected_feature_df = pd.concat([X, y], axis=1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataframe with selected features and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "EzSI-dZiwdXD",
        "outputId": "0f9179c4-b835-48d7-a269-bb0cd95e343a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dd</th>\n",
              "      <th>db</th>\n",
              "      <th>ent_q_diffs_19</th>\n",
              "      <th>ent_q_diffs_median</th>\n",
              "      <th>ent_q_diffs_min</th>\n",
              "      <th>ent_q_diff_diffs_0_median</th>\n",
              "      <th>ent_q_diff_diffs_1_mean</th>\n",
              "      <th>ent_q_diff_diffs_1_median</th>\n",
              "      <th>ent_q_diff_diffs_1_max</th>\n",
              "      <th>ent_q_diff_diffs_1_min</th>\n",
              "      <th>...</th>\n",
              "      <th>dd_rdata</th>\n",
              "      <th>db3_rdata</th>\n",
              "      <th>Img17</th>\n",
              "      <th>Img43</th>\n",
              "      <th>line_count_asm</th>\n",
              "      <th>size_asm</th>\n",
              "      <th>ExtendedAscii</th>\n",
              "      <th>Img106</th>\n",
              "      <th>Img107</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87450.000000</td>\n",
              "      <td>6.387700e+04</td>\n",
              "      <td>0.007111</td>\n",
              "      <td>3.287587</td>\n",
              "      <td>0.935826</td>\n",
              "      <td>3.343766</td>\n",
              "      <td>3.303931</td>\n",
              "      <td>3.303541</td>\n",
              "      <td>3.340287</td>\n",
              "      <td>5694.699627</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022534</td>\n",
              "      <td>0.929824</td>\n",
              "      <td>0.019339</td>\n",
              "      <td>0.019408</td>\n",
              "      <td>118529.000000</td>\n",
              "      <td>6874624.0</td>\n",
              "      <td>15087.00000</td>\n",
              "      <td>171979.000000</td>\n",
              "      <td>162674.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2911.000000</td>\n",
              "      <td>5.817000e+03</td>\n",
              "      <td>0.527049</td>\n",
              "      <td>3.855402</td>\n",
              "      <td>-0.002843</td>\n",
              "      <td>3.724415</td>\n",
              "      <td>3.972226</td>\n",
              "      <td>68333.721912</td>\n",
              "      <td>3.996263</td>\n",
              "      <td>3.920995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136843</td>\n",
              "      <td>0.136971</td>\n",
              "      <td>98253.227205</td>\n",
              "      <td>460288.0</td>\n",
              "      <td>579.00000</td>\n",
              "      <td>7702.000000</td>\n",
              "      <td>6551.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>671.000000</td>\n",
              "      <td>1.367070e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.076682</td>\n",
              "      <td>0.214832</td>\n",
              "      <td>3.111649</td>\n",
              "      <td>3.086481</td>\n",
              "      <td>3.086244</td>\n",
              "      <td>3.135941</td>\n",
              "      <td>3.036401</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270903</td>\n",
              "      <td>0.011148</td>\n",
              "      <td>0.077245</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>90625.000000</td>\n",
              "      <td>5256192.0</td>\n",
              "      <td>385051.00000</td>\n",
              "      <td>151324.169975</td>\n",
              "      <td>12946.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65917.000000</td>\n",
              "      <td>1.319000e+03</td>\n",
              "      <td>0.002677</td>\n",
              "      <td>3.718103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.741434</td>\n",
              "      <td>3.722709</td>\n",
              "      <td>3.728404</td>\n",
              "      <td>3.762014</td>\n",
              "      <td>3.646042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156450</td>\n",
              "      <td>0.477585</td>\n",
              "      <td>0.020483</td>\n",
              "      <td>43831.635751</td>\n",
              "      <td>83201.000000</td>\n",
              "      <td>4825600.0</td>\n",
              "      <td>138.00000</td>\n",
              "      <td>122247.000000</td>\n",
              "      <td>98621.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>106.000000</td>\n",
              "      <td>1.390000e+02</td>\n",
              "      <td>0.392382</td>\n",
              "      <td>3.729796</td>\n",
              "      <td>0.488767</td>\n",
              "      <td>3.685106</td>\n",
              "      <td>3.600971</td>\n",
              "      <td>3.643115</td>\n",
              "      <td>3.742570</td>\n",
              "      <td>2.733127</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287926</td>\n",
              "      <td>0.191950</td>\n",
              "      <td>0.073053</td>\n",
              "      <td>0.072308</td>\n",
              "      <td>12289.000000</td>\n",
              "      <td>712704.0</td>\n",
              "      <td>46020.42304</td>\n",
              "      <td>15501.000000</td>\n",
              "      <td>11864.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>145.000000</td>\n",
              "      <td>8.081200e+04</td>\n",
              "      <td>0.526386</td>\n",
              "      <td>3.890063</td>\n",
              "      <td>-0.003979</td>\n",
              "      <td>3.925258</td>\n",
              "      <td>3.997170</td>\n",
              "      <td>3.997181</td>\n",
              "      <td>3.998172</td>\n",
              "      <td>3.995805</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.956830</td>\n",
              "      <td>0.432878</td>\n",
              "      <td>0.433107</td>\n",
              "      <td>9729.000000</td>\n",
              "      <td>564224.0</td>\n",
              "      <td>38809.00000</td>\n",
              "      <td>7100.000000</td>\n",
              "      <td>6002.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>171.000000</td>\n",
              "      <td>1.625000e+03</td>\n",
              "      <td>0.250124</td>\n",
              "      <td>-0.021744</td>\n",
              "      <td>-0.066759</td>\n",
              "      <td>-0.011146</td>\n",
              "      <td>-0.033653</td>\n",
              "      <td>-0.033653</td>\n",
              "      <td>-0.022400</td>\n",
              "      <td>-0.044906</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098437</td>\n",
              "      <td>0.696875</td>\n",
              "      <td>0.743118</td>\n",
              "      <td>0.743086</td>\n",
              "      <td>252838.342877</td>\n",
              "      <td>11329024.0</td>\n",
              "      <td>136.00000</td>\n",
              "      <td>69304.000000</td>\n",
              "      <td>65638.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>176.000000</td>\n",
              "      <td>3.357940e+04</td>\n",
              "      <td>0.345338</td>\n",
              "      <td>91553.848334</td>\n",
              "      <td>-0.066875</td>\n",
              "      <td>3.989448</td>\n",
              "      <td>1.626240</td>\n",
              "      <td>-0.025468</td>\n",
              "      <td>4.061918</td>\n",
              "      <td>-0.033914</td>\n",
              "      <td>...</td>\n",
              "      <td>0.286364</td>\n",
              "      <td>0.109091</td>\n",
              "      <td>0.636657</td>\n",
              "      <td>0.636735</td>\n",
              "      <td>146689.000000</td>\n",
              "      <td>8507904.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>71789.000000</td>\n",
              "      <td>68354.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>17722.117177</td>\n",
              "      <td>9.175662e+05</td>\n",
              "      <td>0.005243</td>\n",
              "      <td>3.525569</td>\n",
              "      <td>-0.068154</td>\n",
              "      <td>3.560385</td>\n",
              "      <td>3.537350</td>\n",
              "      <td>3.538891</td>\n",
              "      <td>3.572166</td>\n",
              "      <td>3.469215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.995316</td>\n",
              "      <td>0.191754</td>\n",
              "      <td>0.191604</td>\n",
              "      <td>76608.000000</td>\n",
              "      <td>4443250.0</td>\n",
              "      <td>265184.00000</td>\n",
              "      <td>89989.000000</td>\n",
              "      <td>70139.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>501.000000</td>\n",
              "      <td>1.606820e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.112661</td>\n",
              "      <td>55445.814378</td>\n",
              "      <td>3.497945</td>\n",
              "      <td>3.115287</td>\n",
              "      <td>3.115763</td>\n",
              "      <td>3.146756</td>\n",
              "      <td>3.086457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278065</td>\n",
              "      <td>0.012903</td>\n",
              "      <td>0.091974</td>\n",
              "      <td>0.092082</td>\n",
              "      <td>13569.000000</td>\n",
              "      <td>786944.0</td>\n",
              "      <td>43284.00000</td>\n",
              "      <td>9394.000000</td>\n",
              "      <td>3145.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4999 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                dd            db  ent_q_diffs_19  ent_q_diffs_median  \\\n",
              "0     87450.000000  6.387700e+04        0.007111            3.287587   \n",
              "1      2911.000000  5.817000e+03        0.527049            3.855402   \n",
              "2       671.000000  1.367070e+06        0.000000            3.076682   \n",
              "3     65917.000000  1.319000e+03        0.002677            3.718103   \n",
              "4       106.000000  1.390000e+02        0.392382            3.729796   \n",
              "...            ...           ...             ...                 ...   \n",
              "4994    145.000000  8.081200e+04        0.526386            3.890063   \n",
              "4995    171.000000  1.625000e+03        0.250124           -0.021744   \n",
              "4996    176.000000  3.357940e+04        0.345338        91553.848334   \n",
              "4997  17722.117177  9.175662e+05        0.005243            3.525569   \n",
              "4998    501.000000  1.606820e+05        0.000000            3.112661   \n",
              "\n",
              "      ent_q_diffs_min  ent_q_diff_diffs_0_median  ent_q_diff_diffs_1_mean  \\\n",
              "0            0.935826                   3.343766                 3.303931   \n",
              "1           -0.002843                   3.724415                 3.972226   \n",
              "2            0.214832                   3.111649                 3.086481   \n",
              "3            0.000000                   3.741434                 3.722709   \n",
              "4            0.488767                   3.685106                 3.600971   \n",
              "...               ...                        ...                      ...   \n",
              "4994        -0.003979                   3.925258                 3.997170   \n",
              "4995        -0.066759                  -0.011146                -0.033653   \n",
              "4996        -0.066875                   3.989448                 1.626240   \n",
              "4997        -0.068154                   3.560385                 3.537350   \n",
              "4998     55445.814378                   3.497945                 3.115287   \n",
              "\n",
              "      ent_q_diff_diffs_1_median  ent_q_diff_diffs_1_max  \\\n",
              "0                      3.303541                3.340287   \n",
              "1                  68333.721912                3.996263   \n",
              "2                      3.086244                3.135941   \n",
              "3                      3.728404                3.762014   \n",
              "4                      3.643115                3.742570   \n",
              "...                         ...                     ...   \n",
              "4994                   3.997181                3.998172   \n",
              "4995                  -0.033653               -0.022400   \n",
              "4996                  -0.025468                4.061918   \n",
              "4997                   3.538891                3.572166   \n",
              "4998                   3.115763                3.146756   \n",
              "\n",
              "      ent_q_diff_diffs_1_min  ...  dd_rdata  db3_rdata     Img17  \\\n",
              "0                5694.699627  ...  0.022534   0.929824  0.019339   \n",
              "1                   3.920995  ...  0.000000   0.000000  0.136843   \n",
              "2                   3.036401  ...  0.270903   0.011148  0.077245   \n",
              "3                   3.646042  ...  0.156450   0.477585  0.020483   \n",
              "4                   2.733127  ...  0.287926   0.191950  0.073053   \n",
              "...                      ...  ...       ...        ...       ...   \n",
              "4994                3.995805  ...  0.000000   0.956830  0.432878   \n",
              "4995               -0.044906  ...  0.098437   0.696875  0.743118   \n",
              "4996               -0.033914  ...  0.286364   0.109091  0.636657   \n",
              "4997                3.469215  ...  0.000638   0.995316  0.191754   \n",
              "4998                3.086457  ...  0.278065   0.012903  0.091974   \n",
              "\n",
              "             Img43  line_count_asm    size_asm  ExtendedAscii         Img106  \\\n",
              "0         0.019408   118529.000000   6874624.0    15087.00000  171979.000000   \n",
              "1         0.136971    98253.227205    460288.0      579.00000    7702.000000   \n",
              "2         0.077628    90625.000000   5256192.0   385051.00000  151324.169975   \n",
              "3     43831.635751    83201.000000   4825600.0      138.00000  122247.000000   \n",
              "4         0.072308    12289.000000    712704.0    46020.42304   15501.000000   \n",
              "...            ...             ...         ...            ...            ...   \n",
              "4994      0.433107     9729.000000    564224.0    38809.00000    7100.000000   \n",
              "4995      0.743086   252838.342877  11329024.0      136.00000   69304.000000   \n",
              "4996      0.636735   146689.000000   8507904.0        0.00000   71789.000000   \n",
              "4997      0.191604    76608.000000   4443250.0   265184.00000   89989.000000   \n",
              "4998      0.092082    13569.000000    786944.0    43284.00000    9394.000000   \n",
              "\n",
              "        Img107  target  \n",
              "0     162674.0       2  \n",
              "1       6551.0       8  \n",
              "2      12946.0       6  \n",
              "3      98621.0       4  \n",
              "4      11864.0       1  \n",
              "...        ...     ...  \n",
              "4994    6002.0       4  \n",
              "4995   65638.0       3  \n",
              "4996   68354.0       3  \n",
              "4997   70139.0       2  \n",
              "4998    3145.0       9  \n",
              "\n",
              "[4999 rows x 51 columns]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_feature_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbcI7frx41v3"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "LBAmHCru_gub"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4YySDgxvxsSf"
      },
      "source": [
        "**`Applying GridSearch to Random Forest Classifier : Accuracy: 0.896 `**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy was 0.891 before appliyng K-fold."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Always split the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the hyperparameter grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {'n_estimators': np.arange(10, 200, 10),\n",
        "              'max_depth': np.arange(1, 20),\n",
        "              'min_samples_split': np.arange(2, 10),\n",
        "              'min_samples_leaf': np.arange(1, 10)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform k-fold cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=55)\n",
        "accuracies = []\n",
        "best_params = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I added a for loop to iterate over the splits defined by the KFold and perform the random search, evaluation and store the best hyperparameters on each fold."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " accuracies is a list to store the accuracy of each fold and the best hyperparameters of each fold and printed the mean accuracy and the best hyperparameters for each fold at the end of the loop."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform randomized search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    \n",
        "    random_search = RandomizedSearchCV(rfc, param_grid, cv=5, n_iter=25, random_state=42,)\n",
        "    random_search.fit(X_train, y_train)\n",
        "    y_pred = random_search.predict(X_test)# evaluate the model on test data\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "    best_params.append(random_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.895\n",
            "[{'n_estimators': 180, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 17}, {'n_estimators': 180, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 17}, {'n_estimators': 180, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 17}, {'n_estimators': 180, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 17}, {'n_estimators': 180, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 17}]\n"
          ]
        }
      ],
      "source": [
        "print(f'Mean Accuracy: {np.mean(accuracies):.3f}')\n",
        "#best parameters for each fold\n",
        "print(best_params)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**`Applying GridSearch with Decision Tree:Accuracy: 0.842 `**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the data into training and testing sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 3, 4, 5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [3, 4, 5, 6, 7, 8, 9, 10],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 3, 4, 5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=4, estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
              "                         'min_samples_leaf': [1, 2, 3, 4, 5],\n",
              "                         'min_samples_split': [2, 3, 4, 5]})"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the decision tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "              'min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "              'min_samples_split': [2, 3, 4, 5]}\n",
        "\n",
        "# Use grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=4)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To find the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(\"Best hyperparameters: \", best_params)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have to re-initialize the decision tree classifier with the best_params above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(max_depth=best_params['max_depth'],\n",
        "                            min_samples_leaf=best_params['min_samples_leaf'],\n",
        "                            min_samples_split=best_params['min_samples_split'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the classifier to the complete dataset.The grid search is then performed on the training data to find the best hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.845\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.78      0.82      0.80       142\n",
            "           2       0.86      0.95      0.90       206\n",
            "           3       0.93      0.97      0.95       273\n",
            "           4       0.82      0.67      0.74        46\n",
            "           5       0.00      0.00      0.00        15\n",
            "           6       0.71      0.72      0.71        64\n",
            "           7       0.82      0.64      0.72        36\n",
            "           8       0.78      0.72      0.75       125\n",
            "           9       0.88      0.86      0.87        93\n",
            "\n",
            "    accuracy                           0.84      1000\n",
            "   macro avg       0.73      0.70      0.71      1000\n",
            "weighted avg       0.83      0.84      0.84      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(f'Classification Report: {classification_report(y_test, y_pred)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**`Applying GridSearch with Naive Bayes Decision:Accuracy: 0.46 `**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "#replace negative values with their absolute value\n",
        "X = np.abs(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'alpha': 0.1}\n",
            "Accuracy: 0.46\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {'alpha': [0.1, 1, 10]}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(nb, param_grid, cv=4)\n",
        "\n",
        "# Fit the data to the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are several ways to ensemble different models, but I will use voting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Lets Relocate and remind the classifiers.\n",
        "# rfc = Random Forest\n",
        "# dt = Decision Tree\n",
        "# nb = Naive Bayes\n",
        "# Create a list of the classifiers\n",
        "classifiers = [('Random Forest', rfc), ('Decision Tree', dt), ('Naive Bayes', nb)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**`Voting classifier `**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hard voting. Hard Voting Ensemble model accuracy: 0.862"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "voting_clf = VotingClassifier(estimators=classifiers, voting='hard')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the voting classifier to the training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;Decision Tree&#x27;,\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             (&#x27;Naive Bayes&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;Decision Tree&#x27;,\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             (&#x27;Naive Bayes&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Decision Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Naive Bayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('Random Forest', RandomForestClassifier()),\n",
              "                             ('Decision Tree',\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             ('Naive Bayes', MultinomialNB())])"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets make predictions on the test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = voting_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hard Voting Ensemble model accuracy: 0.862\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy of the ensemble model on the test data\n",
        "accuracy = voting_clf.score(X_test, y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Hard Voting Ensemble model accuracy: {:.3f}'.format(accuracy))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Soft voting, same operations. Soft Voting Ensemble model accuracy: 0.861"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "voting_clf = VotingClassifier(estimators=classifiers, voting='soft')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;Decision Tree&#x27;,\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             (&#x27;Naive Bayes&#x27;, MultinomialNB())],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Random Forest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;Decision Tree&#x27;,\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             (&#x27;Naive Bayes&#x27;, MultinomialNB())],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Decision Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=5)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Naive Bayes</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('Random Forest', RandomForestClassifier()),\n",
              "                             ('Decision Tree',\n",
              "                              DecisionTreeClassifier(max_depth=10,\n",
              "                                                     min_samples_leaf=5)),\n",
              "                             ('Naive Bayes', MultinomialNB())],\n",
              "                 voting='soft')"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voting_clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = voting_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soft Voting Ensemble model accuracy: 0.861\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy of the ensemble model on the test data\n",
        "accuracy = voting_clf.score(X_test, y_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print('Soft Voting Ensemble model accuracy: {:.3f}'.format(accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
